{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd03a723",
   "metadata": {
    "papermill": {
     "duration": 0.021466,
     "end_time": "2021-09-18T08:07:54.636482",
     "exception": false,
     "start_time": "2021-09-18T08:07:54.615016",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### What is transfer learning?\n",
    "Transfer learning is a research problem in machine learning that focuses on storing knowledge gained while solving one problem and applying it to a different but related problem. \n",
    "### An example \n",
    "For example, knowledge gained while learning to recognize cars could apply when trying to recognize trucks.'\n",
    "\n",
    "\n",
    "![Transfer Learning](https://miro.medium.com/max/1400/1*9GTEzcO8KxxrfutmtsPs3Q.png)\n",
    "\n",
    "\n",
    "### Explaining it in simple terms, or atleast trying to \n",
    "\n",
    "- With transfer learning, we basically try to exploit what has been learned in one task to improve generalization in another. We transfer the weights that a network has learned at \"task A\" to a new \"task B.\"\n",
    "\n",
    "\n",
    "\n",
    "- The general idea is to use the knowledge a model has learned from a task with a lot of available labeled training data in a new task that doesn't have much data. \n",
    "- Instead of starting the learning process from scratch, we start with patterns learned from solving a related task.\n",
    "\n",
    "- Transfer learning is mostly used in computer vision and natural language processing tasks like sentiment analysis due to the huge amount of computational power required.\n",
    "\n",
    "- Transfer learning isn't really a machine learning technique, but can be seen as a \"design methodology\" within the field, for example, active learning. \n",
    "- It is also not an exclusive part or study-area of machine learning. Nevertheless, it has become quite popular in combination with neural networks that require huge amounts of data and computational power.\n",
    "\n",
    "![](https://cdn.builtin.com/sites/www.builtin.com/files/styles/ckeditor_optimize/public/inline-images/national/AGI-transfer-learning_0.png)\n",
    "\n",
    "\n",
    "\n",
    "##### I will be following the code done on the same dataset by [Ahmed Saied](https://www.kaggle.com/phylake1337) explained in the link [The Code](https://www.kaggle.com/phylake1337/0-18-loss-simple-feature-extractors/notebook)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f62525a",
   "metadata": {
    "papermill": {
     "duration": 0.020095,
     "end_time": "2021-09-18T08:07:54.678955",
     "exception": false,
     "start_time": "2021-09-18T08:07:54.658860",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Introduction\n",
    "\n",
    "* This kernel is a detailed guide for transfer learning on Dog Breeds problem, it's all about learning a new technique, evaluate it using only Kaggle training set without cheating.\n",
    "\n",
    "* The aim of this kernel is to show you how to use pre-trained CNN models as feature extractors, which one of the most effective transfer learning techniques.\n",
    "\n",
    "* A reasonable question comes to your mind, 'Wait, why do we have to use this technique, why don't we just use regular transfer learning ?', if you try to do so, you will figure out that the problem is pretty hard for a single model to handle (you would get higher loss and less accuracy).\n",
    "\n",
    "* It's even hard for humankind to distinguish between 120 dog breeds!, single poor CNN would struggle.\n",
    "\n",
    "### Explanation\n",
    "\n",
    "- Take look at general CNN architecture for image classification in two main parts, “feature extractor” that based on conv-layers, and “classifier” which usually based on fully connected layers:\n",
    "- Simply, feature extractor could be created as follow > (Feature Extractor = Pretrained Model - Late Fully Connected Layers)\n",
    "\n",
    "- For example, InceptionV3 feature extractor (without last FC layer) outputs 2048 vector for each image sample, each value represent a certain feature of dog image (Coded in numerical values of course), like Dog color?, How big is his head?, Shape of the eyes?, length of the tale?, Size? .. etc\n",
    "\n",
    "- Hence, more \"different\" feature extractors mean more features to be used to determine which breed does this dog belong.\n",
    "\n",
    "- So our strategy goes as the following,\n",
    "\n",
    " - Create 4 feature extractor using different pre-trained CNN models\n",
    " - Extract features from raw data and stacks the features together.\n",
    " - Use a simple DNN with one dense layer and a heavy dropout layer to figure out patterns in the feature extracted from the data.\n",
    " - The code is simple, concise and fully-commented. Feel free to ask for help / more info / more explanation in the comments.\n",
    "\n",
    "- Finally if this kernel helps you somehow, kindly don't forget to leave a little upvote.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf06fd66",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-09-18T08:07:54.801854Z",
     "iopub.status.busy": "2021-09-18T08:07:54.801128Z",
     "iopub.status.idle": "2021-09-18T08:07:59.552284Z",
     "shell.execute_reply": "2021-09-18T08:07:59.551306Z",
     "shell.execute_reply.started": "2021-09-18T07:26:09.682096Z"
    },
    "papermill": {
     "duration": 4.853241,
     "end_time": "2021-09-18T08:07:59.552455",
     "exception": false,
     "start_time": "2021-09-18T08:07:54.699214",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-18 08:07:55.426907: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os, cv2, random, time, shutil, csv\n",
    "import tensorflow as tf\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from tqdm import tqdm\n",
    "np.random.seed(42)\n",
    "%matplotlib inline \n",
    "\n",
    "import tensorflow.keras\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import BatchNormalization, Dense, GlobalAveragePooling2D, Lambda, Dropout, InputLayer, Input\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.image import load_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e6c03b6b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-18T08:07:59.601090Z",
     "iopub.status.busy": "2021-09-18T08:07:59.599496Z",
     "iopub.status.idle": "2021-09-18T08:07:59.601677Z",
     "shell.execute_reply": "2021-09-18T08:07:59.602091Z",
     "shell.execute_reply.started": "2021-09-18T07:26:14.825226Z"
    },
    "papermill": {
     "duration": 0.027558,
     "end_time": "2021-09-18T08:07:59.602216",
     "exception": false,
     "start_time": "2021-09-18T08:07:59.574658",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_num_files(path):\n",
    "    '''\n",
    "    Counts the number of files in a folder.\n",
    "    '''\n",
    "    if not os.path.exists(path):\n",
    "        return 0\n",
    "    return sum([len(files) for r, d, files in os.walk(path)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e19e002",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-18T08:07:59.647033Z",
     "iopub.status.busy": "2021-09-18T08:07:59.646315Z",
     "iopub.status.idle": "2021-09-18T08:08:24.229669Z",
     "shell.execute_reply": "2021-09-18T08:08:24.229199Z",
     "shell.execute_reply.started": "2021-09-18T07:26:14.833377Z"
    },
    "papermill": {
     "duration": 24.607215,
     "end_time": "2021-09-18T08:08:24.229808",
     "exception": false,
     "start_time": "2021-09-18T08:07:59.622593",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data samples size:  10222\n",
      "Test samples size:  10357\n"
     ]
    }
   ],
   "source": [
    "#Data Paths\n",
    "train_dir = '/kaggle/input/dog-breed-identification/train'\n",
    "test_dir = '/kaggle/input/dog-breed-identification/test'\n",
    "#Count/Print train and test samples.\n",
    "data_size = get_num_files(train_dir)\n",
    "test_size = get_num_files(test_dir)\n",
    "print('Data samples size: ', data_size)\n",
    "print('Test samples size: ', test_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6307c36c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-18T08:08:24.276403Z",
     "iopub.status.busy": "2021-09-18T08:08:24.275822Z",
     "iopub.status.idle": "2021-09-18T08:08:24.782278Z",
     "shell.execute_reply": "2021-09-18T08:08:24.781823Z",
     "shell.execute_reply.started": "2021-09-18T07:46:48.965895Z"
    },
    "papermill": {
     "duration": 0.53138,
     "end_time": "2021-09-18T08:08:24.782414",
     "exception": false,
     "start_time": "2021-09-18T08:08:24.251034",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>breed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000bec180eb18c7604dcecc8fe0dba07</td>\n",
       "      <td>boston_bull</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 id        breed\n",
       "0  000bec180eb18c7604dcecc8fe0dba07  boston_bull"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Read train labels.\n",
    "labels_dataframe = pd.read_csv('/kaggle/input/dog-breed-identification/labels.csv')\n",
    "#Read sample_submission file to be modified by pridected labels.\n",
    "sample_df = pd.read_csv('/kaggle/input/dog-breed-identification/sample_submission.csv')\n",
    "#Incpect labels_dataframe.\n",
    "labels_dataframe.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f6375a29",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-18T08:08:24.830709Z",
     "iopub.status.busy": "2021-09-18T08:08:24.830194Z",
     "iopub.status.idle": "2021-09-18T08:08:24.833462Z",
     "shell.execute_reply": "2021-09-18T08:08:24.833829Z",
     "shell.execute_reply.started": "2021-09-18T07:26:27.767081Z"
    },
    "papermill": {
     "duration": 0.030304,
     "end_time": "2021-09-18T08:08:24.833983",
     "exception": false,
     "start_time": "2021-09-18T08:08:24.803679",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Create list of alphabetically sorted labels.\n",
    "dog_breeds = sorted(list(set(labels_dataframe['breed'])))\n",
    "n_classes = len(dog_breeds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f76a82a9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-18T08:08:24.895291Z",
     "iopub.status.busy": "2021-09-18T08:08:24.894653Z",
     "iopub.status.idle": "2021-09-18T08:08:25.118354Z",
     "shell.execute_reply": "2021-09-18T08:08:25.117828Z",
     "shell.execute_reply.started": "2021-09-18T07:26:27.775232Z"
    },
    "papermill": {
     "duration": 0.263492,
     "end_time": "2021-09-18T08:08:25.118480",
     "exception": false,
     "start_time": "2021-09-18T08:08:24.854988",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "\n",
    "sns.color_palette(\"light:#5A9\", as_cmap=True)\n",
    "fig, ax = plt.subplots()\n",
    "fig.set_size_inches(16, 8)\n",
    "sns.set_theme(style=\"darkgrid\")\n",
    "ax = sns.countplot(x=\"breed\", data=labels_dataframe,palette=\"light:#5A9\",order=labels_dataframe.breed.value_counts().iloc[:5].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e9a610bb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-18T08:08:25.165988Z",
     "iopub.status.busy": "2021-09-18T08:08:25.165218Z",
     "iopub.status.idle": "2021-09-18T08:08:25.167204Z",
     "shell.execute_reply": "2021-09-18T08:08:25.167561Z",
     "shell.execute_reply.started": "2021-09-18T07:26:28.025645Z"
    },
    "papermill": {
     "duration": 0.027414,
     "end_time": "2021-09-18T08:08:25.167679",
     "exception": false,
     "start_time": "2021-09-18T08:08:25.140265",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Map each label string to an integer label.\n",
    "class_to_num = dict(zip(dog_breeds, range(n_classes)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8b98eb1a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-18T08:08:25.220226Z",
     "iopub.status.busy": "2021-09-18T08:08:25.218672Z",
     "iopub.status.idle": "2021-09-18T08:08:25.220869Z",
     "shell.execute_reply": "2021-09-18T08:08:25.221280Z",
     "shell.execute_reply.started": "2021-09-18T07:26:28.032459Z"
    },
    "papermill": {
     "duration": 0.032158,
     "end_time": "2021-09-18T08:08:25.221392",
     "exception": false,
     "start_time": "2021-09-18T08:08:25.189234",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def images_to_array(data_dir, labels_dataframe, img_size = (224,224,3)):\n",
    "    '''\n",
    "    1- Read image samples from certain directory.\n",
    "    2- Risize it, then stack them into one big numpy array.\n",
    "    3- Read sample's label form the labels dataframe.\n",
    "    4- One hot encode labels array.\n",
    "    5- Shuffle Data and label arrays.\n",
    "    '''\n",
    "    images_names = labels_dataframe['id']\n",
    "    images_labels = labels_dataframe['breed']\n",
    "    data_size = len(images_names)\n",
    "    #initailize output arrays.\n",
    "    X = np.zeros([data_size, img_size[0], img_size[1], img_size[2]], dtype=np.uint8)\n",
    "    y = np.zeros([data_size,1], dtype=np.uint8)\n",
    "    #read data and lables.\n",
    "    for i in tqdm(range(data_size)):\n",
    "        image_name = images_names[i]\n",
    "        img_dir = os.path.join(data_dir, image_name+'.jpg')\n",
    "        img_pixels = load_img(img_dir, target_size=img_size)\n",
    "        X[i] = img_pixels\n",
    "        \n",
    "        image_breed = images_labels[i]\n",
    "        y[i] = class_to_num[image_breed]\n",
    "    \n",
    "    #One hot encoder\n",
    "    y = to_categorical(y)\n",
    "    #shuffle    \n",
    "    ind = np.random.permutation(data_size)\n",
    "    X = X[ind]\n",
    "    y = y[ind]\n",
    "    print('Ouptut Data Size: ', X.shape)\n",
    "    print('Ouptut Label Size: ', y.shape)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "07d5a97b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-18T08:08:25.268262Z",
     "iopub.status.busy": "2021-09-18T08:08:25.267587Z",
     "iopub.status.idle": "2021-09-18T08:09:42.689109Z",
     "shell.execute_reply": "2021-09-18T08:09:42.689692Z",
     "shell.execute_reply.started": "2021-09-18T07:26:28.04587Z"
    },
    "papermill": {
     "duration": 77.446952,
     "end_time": "2021-09-18T08:09:42.689881",
     "exception": false,
     "start_time": "2021-09-18T08:08:25.242929",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10222/10222 [01:16<00:00, 133.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ouptut Data Size:  (10222, 331, 331, 3)\n",
      "Ouptut Label Size:  (10222, 120)\n"
     ]
    }
   ],
   "source": [
    "#img_size chosen to be 331 to suit the used architectures.\n",
    "img_size = (331,331,3)\n",
    "X, y = images_to_array(train_dir, labels_dataframe, img_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f6295fba",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-18T08:09:43.091862Z",
     "iopub.status.busy": "2021-09-18T08:09:43.091082Z",
     "iopub.status.idle": "2021-09-18T08:09:43.093084Z",
     "shell.execute_reply": "2021-09-18T08:09:43.093451Z",
     "shell.execute_reply.started": "2021-09-18T07:27:41.957265Z"
    },
    "papermill": {
     "duration": 0.205889,
     "end_time": "2021-09-18T08:09:43.093579",
     "exception": false,
     "start_time": "2021-09-18T08:09:42.887690",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_features(model_name, data_preprocessor, input_size, data):\n",
    "    '''\n",
    "    1- Create a feature extractor to extract features from the data.\n",
    "    2- Returns the extracted features and the feature extractor.\n",
    "    '''\n",
    "    #Prepare pipeline.\n",
    "    input_layer = Input(input_size)\n",
    "    preprocessor = Lambda(data_preprocessor)(input_layer)\n",
    "    base_model = model_name(weights='imagenet', include_top=False,\n",
    "                            input_shape=input_size)(preprocessor)\n",
    "    avg = GlobalAveragePooling2D()(base_model)\n",
    "    feature_extractor = Model(inputs = input_layer, outputs = avg)\n",
    "    #Extract feature.\n",
    "    feature_maps = feature_extractor.predict(data, batch_size=64, verbose=1)\n",
    "    print('Feature maps shape: ', feature_maps.shape)\n",
    "    return feature_maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cfb13853",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-18T08:09:43.500948Z",
     "iopub.status.busy": "2021-09-18T08:09:43.500219Z",
     "iopub.status.idle": "2021-09-18T08:10:24.035021Z",
     "shell.execute_reply": "2021-09-18T08:10:24.035681Z",
     "shell.execute_reply.started": "2021-09-18T07:27:41.965871Z"
    },
    "papermill": {
     "duration": 40.73888,
     "end_time": "2021-09-18T08:10:24.035891",
     "exception": false,
     "start_time": "2021-09-18T08:09:43.297011",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-18 08:09:43.528034: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2021-09-18 08:09:43.530370: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
      "2021-09-18 08:09:43.583269: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-09-18 08:09:43.583928: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:00:04.0 name: Tesla P100-PCIE-16GB computeCapability: 6.0\n",
      "coreClock: 1.3285GHz coreCount: 56 deviceMemorySize: 15.90GiB deviceMemoryBandwidth: 681.88GiB/s\n",
      "2021-09-18 08:09:43.584009: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-09-18 08:09:43.607498: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n",
      "2021-09-18 08:09:43.607597: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n",
      "2021-09-18 08:09:43.624144: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2021-09-18 08:09:43.650288: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2021-09-18 08:09:43.673783: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2021-09-18 08:09:43.679954: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11\n",
      "2021-09-18 08:09:43.682249: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n",
      "2021-09-18 08:09:43.682433: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-09-18 08:09:43.683123: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-09-18 08:09:43.684798: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
      "2021-09-18 08:09:43.685255: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-09-18 08:09:43.685458: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2021-09-18 08:09:43.685621: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-09-18 08:09:43.686205: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:00:04.0 name: Tesla P100-PCIE-16GB computeCapability: 6.0\n",
      "coreClock: 1.3285GHz coreCount: 56 deviceMemorySize: 15.90GiB deviceMemoryBandwidth: 681.88GiB/s\n",
      "2021-09-18 08:09:43.686249: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-09-18 08:09:43.686276: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n",
      "2021-09-18 08:09:43.686302: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n",
      "2021-09-18 08:09:43.686319: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2021-09-18 08:09:43.686336: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2021-09-18 08:09:43.686354: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2021-09-18 08:09:43.686381: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11\n",
      "2021-09-18 08:09:43.686413: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n",
      "2021-09-18 08:09:43.686495: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-09-18 08:09:43.687117: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-09-18 08:09:43.687655: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
      "2021-09-18 08:09:43.688704: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-09-18 08:09:44.946420: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2021-09-18 08:09:44.946463: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 \n",
      "2021-09-18 08:09:44.946473: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N \n",
      "2021-09-18 08:09:44.948721: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-09-18 08:09:44.949517: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-09-18 08:09:44.950193: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-09-18 08:09:44.950759: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14957 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "87916544/87910968 [==============================] - 0s 0us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-18 08:09:48.244657: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 3359797626 exceeds 10% of free system memory.\n",
      "2021-09-18 08:09:50.808944: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
      "2021-09-18 08:09:50.818827: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2000185000 Hz\n",
      "2021-09-18 08:09:52.124011: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n",
      "2021-09-18 08:09:57.509926: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n",
      "2021-09-18 08:09:58.151328: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/160 [==============================] - 33s 155ms/step\n",
      "Feature maps shape:  (10222, 2048)\n"
     ]
    }
   ],
   "source": [
    "# Extract features using InceptionV3 as extractor.\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3, preprocess_input\n",
    "inception_preprocessor = preprocess_input\n",
    "inception_features = get_features(InceptionV3,\n",
    "                                  inception_preprocessor,\n",
    "                                  img_size, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "84f29f7c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-18T08:10:24.602940Z",
     "iopub.status.busy": "2021-09-18T08:10:24.602017Z",
     "iopub.status.idle": "2021-09-18T08:11:19.051319Z",
     "shell.execute_reply": "2021-09-18T08:11:19.050695Z",
     "shell.execute_reply.started": "2021-09-18T07:28:22.508447Z"
    },
    "papermill": {
     "duration": 54.766675,
     "end_time": "2021-09-18T08:11:19.051460",
     "exception": false,
     "start_time": "2021-09-18T08:10:24.284785",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/xception/xception_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "83689472/83683744 [==============================] - 1s 0us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-18 08:10:27.078806: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 3359797626 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/160 [==============================] - 49s 299ms/step\n",
      "Feature maps shape:  (10222, 2048)\n"
     ]
    }
   ],
   "source": [
    "# Extract features using Xception as extractor.\n",
    "from tensorflow.keras.applications.xception import Xception, preprocess_input\n",
    "xception_preprocessor = preprocess_input\n",
    "xception_features = get_features(Xception,\n",
    "                                 xception_preprocessor,\n",
    "                                 img_size, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "99dff815",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-18T08:11:19.632030Z",
     "iopub.status.busy": "2021-09-18T08:11:19.631222Z",
     "iopub.status.idle": "2021-09-18T08:12:48.652515Z",
     "shell.execute_reply": "2021-09-18T08:12:48.653078Z",
     "shell.execute_reply.started": "2021-09-18T07:29:16.184449Z"
    },
    "papermill": {
     "duration": 89.314496,
     "end_time": "2021-09-18T08:12:48.653256",
     "exception": false,
     "start_time": "2021-09-18T08:11:19.338760",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet152v2_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "234553344/234545216 [==============================] - 1s 0us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-18 08:11:25.545410: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 3359797626 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/160 [==============================] - 80s 485ms/step\n",
      "Feature maps shape:  (10222, 2048)\n"
     ]
    }
   ],
   "source": [
    "# Extract features using ResNet152V2 as extractor.\n",
    "from tensorflow.keras.applications.resnet_v2 import ResNet152V2, preprocess_input\n",
    "resnet_preprocessor = preprocess_input\n",
    "resnet_features = get_features(ResNet152V2,\n",
    "                               resnet_preprocessor,\n",
    "                               img_size, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aaddbe3d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-18T08:12:49.417494Z",
     "iopub.status.busy": "2021-09-18T08:12:49.416670Z",
     "iopub.status.idle": "2021-09-18T08:16:00.683851Z",
     "shell.execute_reply": "2021-09-18T08:16:00.684323Z",
     "shell.execute_reply.started": "2021-09-18T07:30:45.330432Z"
    },
    "papermill": {
     "duration": 191.674882,
     "end_time": "2021-09-18T08:16:00.684494",
     "exception": false,
     "start_time": "2021-09-18T08:12:49.009612",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/nasnet/NASNet-large-no-top.h5\n",
      "343613440/343610240 [==============================] - 2s 0us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-18 08:13:00.680408: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 3359797626 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/160 [==============================] - 177s 1s/step\n",
      "Feature maps shape:  (10222, 4032)\n"
     ]
    }
   ],
   "source": [
    "# Extract features using NASNetLarge as extractor.\n",
    "from tensorflow.keras.applications.nasnet import NASNetLarge, preprocess_input\n",
    "nasnet_preprocessor = preprocess_input\n",
    "nasnet_features = get_features(NASNetLarge,\n",
    "                               nasnet_preprocessor,\n",
    "                               img_size, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1e8839eb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-18T08:16:01.471863Z",
     "iopub.status.busy": "2021-09-18T08:16:01.470481Z",
     "iopub.status.idle": "2021-09-18T08:17:16.208673Z",
     "shell.execute_reply": "2021-09-18T08:17:16.208073Z",
     "shell.execute_reply.started": "2021-09-18T07:33:56.473448Z"
    },
    "papermill": {
     "duration": 75.133651,
     "end_time": "2021-09-18T08:17:16.208835",
     "exception": false,
     "start_time": "2021-09-18T08:16:01.075184",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_resnet_v2/inception_resnet_v2_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "219062272/219055592 [==============================] - 1s 0us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-18 08:16:09.067452: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 3359797626 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/160 [==============================] - 65s 380ms/step\n",
      "Feature maps shape:  (10222, 1536)\n"
     ]
    }
   ],
   "source": [
    "# Extract features using InceptionResNetV2 as extractor.\n",
    "from tensorflow.keras.applications.inception_resnet_v2 import InceptionResNetV2, preprocess_input\n",
    "inc_resnet_preprocessor = preprocess_input\n",
    "inc_resnet_features = get_features(InceptionResNetV2,\n",
    "                                   inc_resnet_preprocessor,\n",
    "                                   img_size, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0e449730",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-18T08:17:17.103082Z",
     "iopub.status.busy": "2021-09-18T08:17:17.102522Z",
     "iopub.status.idle": "2021-09-18T08:17:17.105982Z",
     "shell.execute_reply": "2021-09-18T08:17:17.106625Z",
     "shell.execute_reply.started": "2021-09-18T07:35:11.063008Z"
    },
    "papermill": {
     "duration": 0.450154,
     "end_time": "2021-09-18T08:17:17.106759",
     "exception": false,
     "start_time": "2021-09-18T08:17:16.656605",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#It's a good habit to free up some RAM memory.\n",
    "#X variable won't be needed anymore, so let's get rid of it.\n",
    "del X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b5d8c4bd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-18T08:17:17.980170Z",
     "iopub.status.busy": "2021-09-18T08:17:17.979033Z",
     "iopub.status.idle": "2021-09-18T08:17:18.155994Z",
     "shell.execute_reply": "2021-09-18T08:17:18.156407Z",
     "shell.execute_reply.started": "2021-09-18T07:35:11.076392Z"
    },
    "papermill": {
     "duration": 0.614955,
     "end_time": "2021-09-18T08:17:18.156548",
     "exception": false,
     "start_time": "2021-09-18T08:17:17.541593",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final feature maps shape (10222, 11712)\n"
     ]
    }
   ],
   "source": [
    "final_features = np.concatenate([inception_features,\n",
    "                                 xception_features,\n",
    "                                 resnet_features,\n",
    "                                 nasnet_features,\n",
    "                                 inc_resnet_features,], axis=-1)\n",
    "print('Final feature maps shape', final_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c73d0f67",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-18T08:17:19.038528Z",
     "iopub.status.busy": "2021-09-18T08:17:19.037665Z",
     "iopub.status.idle": "2021-09-18T08:17:19.039676Z",
     "shell.execute_reply": "2021-09-18T08:17:19.040060Z",
     "shell.execute_reply.started": "2021-09-18T07:35:11.267757Z"
    },
    "papermill": {
     "duration": 0.447563,
     "end_time": "2021-09-18T08:17:19.040193",
     "exception": false,
     "start_time": "2021-09-18T08:17:18.592630",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "#Prepare call backs\n",
    "EarlyStop_callback = tensorflow.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "my_callback=[EarlyStop_callback]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a3fddd94",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-18T08:17:20.153356Z",
     "iopub.status.busy": "2021-09-18T08:17:20.152514Z",
     "iopub.status.idle": "2021-09-18T08:17:25.574990Z",
     "shell.execute_reply": "2021-09-18T08:17:25.574047Z",
     "shell.execute_reply.started": "2021-09-18T07:35:11.274994Z"
    },
    "papermill": {
     "duration": 6.075507,
     "end_time": "2021-09-18T08:17:25.575117",
     "exception": false,
     "start_time": "2021-09-18T08:17:19.499610",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 1.9930 - accuracy: 0.6089 - val_loss: 0.2164 - val_accuracy: 0.9306\n",
      "Epoch 2/60\n",
      "72/72 [==============================] - 0s 5ms/step - loss: 0.1743 - accuracy: 0.9436 - val_loss: 0.2272 - val_accuracy: 0.9296\n",
      "Epoch 3/60\n",
      "72/72 [==============================] - 0s 5ms/step - loss: 0.1294 - accuracy: 0.9583 - val_loss: 0.2247 - val_accuracy: 0.9296\n",
      "Epoch 4/60\n",
      "72/72 [==============================] - 0s 5ms/step - loss: 0.1021 - accuracy: 0.9672 - val_loss: 0.2404 - val_accuracy: 0.9247\n",
      "Epoch 5/60\n",
      "72/72 [==============================] - 0s 5ms/step - loss: 0.0794 - accuracy: 0.9731 - val_loss: 0.2294 - val_accuracy: 0.9296\n",
      "Epoch 6/60\n",
      "72/72 [==============================] - 0s 5ms/step - loss: 0.0620 - accuracy: 0.9801 - val_loss: 0.2341 - val_accuracy: 0.9267\n",
      "Epoch 7/60\n",
      "72/72 [==============================] - 0s 5ms/step - loss: 0.0531 - accuracy: 0.9833 - val_loss: 0.2382 - val_accuracy: 0.9345\n",
      "Epoch 8/60\n",
      "72/72 [==============================] - 0s 5ms/step - loss: 0.0470 - accuracy: 0.9846 - val_loss: 0.2353 - val_accuracy: 0.9306\n",
      "Epoch 9/60\n",
      "72/72 [==============================] - 0s 5ms/step - loss: 0.0408 - accuracy: 0.9860 - val_loss: 0.2406 - val_accuracy: 0.9326\n",
      "Epoch 10/60\n",
      "72/72 [==============================] - 0s 5ms/step - loss: 0.0337 - accuracy: 0.9906 - val_loss: 0.2353 - val_accuracy: 0.9384\n",
      "Epoch 11/60\n",
      "72/72 [==============================] - 0s 5ms/step - loss: 0.0322 - accuracy: 0.9889 - val_loss: 0.2485 - val_accuracy: 0.9326\n"
     ]
    }
   ],
   "source": [
    "#Prepare DNN model\n",
    "dnn = tensorflow.keras.models.Sequential([\n",
    "    InputLayer(final_features.shape[1:]),\n",
    "    Dropout(0.7),\n",
    "    Dense(n_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "dnn.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "#Train simple DNN on extracted features.\n",
    "h = dnn.fit(final_features, y,\n",
    "            batch_size=128,\n",
    "            epochs=60,\n",
    "            validation_split=0.1,\n",
    "            callbacks=my_callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97f4feb1",
   "metadata": {
    "papermill": {
     "duration": 0.459888,
     "end_time": "2021-09-18T08:17:26.488435",
     "exception": false,
     "start_time": "2021-09-18T08:17:26.028547",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fef839db",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-18T08:17:27.403401Z",
     "iopub.status.busy": "2021-09-18T08:17:27.402693Z",
     "iopub.status.idle": "2021-09-18T08:18:22.317546Z",
     "shell.execute_reply": "2021-09-18T08:18:22.318131Z",
     "shell.execute_reply.started": "2021-09-18T07:35:17.815116Z"
    },
    "papermill": {
     "duration": 55.378049,
     "end_time": "2021-09-18T08:18:22.318349",
     "exception": false,
     "start_time": "2021-09-18T08:17:26.940300",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5357/5357 [00:54<00:00, 97.58it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ouptut Data Size:  (5357, 331, 331, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def images_to_array2(data_dir, labels_dataframe, img_size = (224,224,3)):\n",
    "    '''\n",
    "    Do same as images_to_array but omit some unnecessary steps for test data.\n",
    "    '''\n",
    "    images_names = labels_dataframe['id']\n",
    "    data_size = len(images_names)-5000\n",
    "    X = np.zeros([data_size, img_size[0], img_size[1], 3], dtype=np.uint8)\n",
    "    \n",
    "    for i in tqdm(range(data_size)):\n",
    "        image_name = images_names[i]\n",
    "        img_dir = os.path.join(data_dir, image_name+'.jpg')\n",
    "        img_pixels = tf.keras.preprocessing.image.load_img(img_dir, target_size=img_size)\n",
    "        X[i] = img_pixels\n",
    "        \n",
    "    print('Ouptut Data Size: ', X.shape)\n",
    "    return X\n",
    "\n",
    "test_data = images_to_array2(test_dir, sample_df, img_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2a73b5bd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-18T08:18:23.550356Z",
     "iopub.status.busy": "2021-09-18T08:18:23.548696Z",
     "iopub.status.idle": "2021-09-18T08:18:23.550989Z",
     "shell.execute_reply": "2021-09-18T08:18:23.551392Z",
     "shell.execute_reply.started": "2021-09-18T07:35:55.727486Z"
    },
    "papermill": {
     "duration": 0.639454,
     "end_time": "2021-09-18T08:18:23.551516",
     "exception": false,
     "start_time": "2021-09-18T08:18:22.912062",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# del sample_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2b43f7da",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-18T08:18:24.801866Z",
     "iopub.status.busy": "2021-09-18T08:18:24.800636Z",
     "iopub.status.idle": "2021-09-18T08:22:32.183365Z",
     "shell.execute_reply": "2021-09-18T08:22:32.183923Z",
     "shell.execute_reply.started": "2021-09-18T07:41:35.609968Z"
    },
    "papermill": {
     "duration": 247.992725,
     "end_time": "2021-09-18T08:22:32.184131",
     "exception": false,
     "start_time": "2021-09-18T08:18:24.191406",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84/84 [==============================] - 14s 160ms/step\n",
      "Feature maps shape:  (5357, 2048)\n",
      "84/84 [==============================] - 26s 305ms/step\n",
      "Feature maps shape:  (5357, 2048)\n",
      "84/84 [==============================] - 43s 494ms/step\n",
      "Feature maps shape:  (5357, 2048)\n",
      "84/84 [==============================] - 95s 1s/step\n",
      "Feature maps shape:  (5357, 4032)\n",
      "84/84 [==============================] - 35s 386ms/step\n",
      "Feature maps shape:  (5357, 1536)\n",
      "Final feature maps shape (5357, 11712)\n"
     ]
    }
   ],
   "source": [
    "#Extract test data features.\n",
    "inception_features = get_features(InceptionV3, inception_preprocessor, img_size, test_data)\n",
    "xception_features = get_features(Xception, xception_preprocessor, img_size, test_data)\n",
    "resnet_features = get_features(ResNet152V2, resnet_preprocessor, img_size, test_data)\n",
    "nasnet_features = get_features(NASNetLarge, nasnet_preprocessor, img_size, test_data)\n",
    "inc_resnet_features = get_features(InceptionResNetV2, inc_resnet_preprocessor, img_size, test_data)\n",
    "\n",
    "test_features = np.concatenate([inception_features,\n",
    "                                 xception_features,\n",
    "                                 resnet_features,\n",
    "                                 nasnet_features,\n",
    "                                 inc_resnet_features],axis=-1)\n",
    "print('Final feature maps shape', test_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3fda6b1c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-18T08:22:33.656482Z",
     "iopub.status.busy": "2021-09-18T08:22:33.655846Z",
     "iopub.status.idle": "2021-09-18T08:22:33.658978Z",
     "shell.execute_reply": "2021-09-18T08:22:33.658564Z",
     "shell.execute_reply.started": "2021-09-18T07:45:41.767769Z"
    },
    "papermill": {
     "duration": 0.755837,
     "end_time": "2021-09-18T08:22:33.659094",
     "exception": false,
     "start_time": "2021-09-18T08:22:32.903257",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Free up some space.\n",
    "del test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6bc4429e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-18T08:22:35.030358Z",
     "iopub.status.busy": "2021-09-18T08:22:35.029644Z",
     "iopub.status.idle": "2021-09-18T08:22:35.381627Z",
     "shell.execute_reply": "2021-09-18T08:22:35.381117Z",
     "shell.execute_reply.started": "2021-09-18T07:46:07.872983Z"
    },
    "papermill": {
     "duration": 1.037851,
     "end_time": "2021-09-18T08:22:35.381749",
     "exception": false,
     "start_time": "2021-09-18T08:22:34.343898",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Predict test labels given test data features.\n",
    "y_pred = dnn.predict(test_features, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "dd3f52fc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-18T08:22:36.776503Z",
     "iopub.status.busy": "2021-09-18T08:22:36.775826Z",
     "iopub.status.idle": "2021-09-18T08:22:37.714919Z",
     "shell.execute_reply": "2021-09-18T08:22:37.714420Z",
     "shell.execute_reply.started": "2021-09-18T07:47:18.166164Z"
    },
    "papermill": {
     "duration": 1.64548,
     "end_time": "2021-09-18T08:22:37.715053",
     "exception": false,
     "start_time": "2021-09-18T08:22:36.069573",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Create submission file\n",
    "sample_df = sample_df.head(5357)\n",
    "for b in dog_breeds:\n",
    "    sample_df[b] = y_pred[:,class_to_num[b]]\n",
    "sample_df.to_csv('pred.csv', index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a8392e1",
   "metadata": {
    "papermill": {
     "duration": 0.902974,
     "end_time": "2021-09-18T08:22:39.306293",
     "exception": false,
     "start_time": "2021-09-18T08:22:38.403319",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "If there are any suggesion for the notebook please comment, that would be helpful. Also please upvote if you liked it! Thank you!!\n",
    "\n",
    "Some of my other works:\n",
    "\n",
    "* [TPS- APR](https://www.kaggle.com/udbhavpangotra/tps-apr21-eda-model) \n",
    "* [HEART ATTACKS](https://www.kaggle.com/udbhavpangotra/heart-attacks-extensive-eda-and-visualizations) \n",
    "* [YOUTUBE DATA EXPLORATION](https://www.kaggle.com/udbhavpangotra/what-do-people-use-youtube-for-in-great-britain)\n",
    "* [TPS MAY](https://www.kaggle.com/udbhavpangotra/tps-may-21-extensive-eda-catboost-shap)\n",
    "* [COVID-19 DIGITAL LEARNING](https://www.kaggle.com/udbhavpangotra/how-did-covid-19-impact-digital-learning-eda)\n",
    "* [TPS - SEPT](https://www.kaggle.com/udbhavpangotra/extensive-eda-baseline-shap)\n",
    "* [EDA - Wikimedia Image/Caption Matching](https://www.kaggle.com/udbhavpangotra/eda-wikimedia-image-caption-matching)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Dataset \n",
    "* [also try this dataset ReliefWeb Crisis Figures Data](https://www.kaggle.com/udbhavpangotra/reliefweb-crisis-figures-data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "76eab43b",
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2021-09-18T08:22:40.689511Z",
     "iopub.status.busy": "2021-09-18T08:22:40.688628Z",
     "iopub.status.idle": "2021-09-18T08:22:40.693019Z",
     "shell.execute_reply": "2021-09-18T08:22:40.692606Z",
     "shell.execute_reply.started": "2021-09-18T07:49:27.119014Z"
    },
    "papermill": {
     "duration": 0.701234,
     "end_time": "2021-09-18T08:22:40.693131",
     "exception": false,
     "start_time": "2021-09-18T08:22:39.991897",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<marquee style='width: 90% ;height:70%; color: #45B39D ;'>\n",
       "    <b>Do UPVOTE if you like my work!  :) </b></marquee>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<marquee style='width: 90% ;height:70%; color: #45B39D ;'>\n",
    "    <b>Do UPVOTE if you like my work!  :) </b></marquee>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb25bb33",
   "metadata": {
    "papermill": {
     "duration": 0.684783,
     "end_time": "2021-09-18T08:22:42.063167",
     "exception": false,
     "start_time": "2021-09-18T08:22:41.378384",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 897.996819,
   "end_time": "2021-09-18T08:22:46.376430",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-09-18T08:07:48.379611",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
